{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "786a1bae-ff98-4298-bf8a-559e426093df",
   "metadata": {},
   "source": [
    "## Install necessary packages and Import libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6777df02-eb7c-43ed-a8dd-d51223db13bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (23.3.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bdc9675-58f3-4dc2-806e-4f933e4c0c00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker==2.194.0 in /opt/conda/lib/python3.10/site-packages (2.194.0)\n",
      "Requirement already satisfied: boto3 in /opt/conda/lib/python3.10/site-packages (1.28.73)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.34.1)\n",
      "Requirement already satisfied: PyMuPDF in /opt/conda/lib/python3.10/site-packages (1.23.5)\n",
      "Requirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.0.326)\n",
      "Requirement already satisfied: attrs<24,>=23.1.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (23.1.0)\n",
      "Requirement already satisfied: cloudpickle==2.2.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (2.2.1)\n",
      "Requirement already satisfied: google-pasta in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (1.26.0)\n",
      "Requirement already satisfied: protobuf<5.0,>=3.12 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (4.24.4)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (1.0.1)\n",
      "Requirement already satisfied: importlib-metadata<7.0,>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (4.11.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (21.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (1.4.4)\n",
      "Requirement already satisfied: pathos in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (0.3.1)\n",
      "Requirement already satisfied: schema in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (0.7.5)\n",
      "Requirement already satisfied: PyYAML~=6.0 in /opt/conda/lib/python3.10/site-packages/PyYAML-6.0-py3.10-linux-x86_64.egg (from sagemaker==2.194.0) (6.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (4.19.1)\n",
      "Requirement already satisfied: platformdirs in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (2.5.2)\n",
      "Requirement already satisfied: tblib==1.7.0 in /opt/conda/lib/python3.10/site-packages (from sagemaker==2.194.0) (1.7.0)\n",
      "Requirement already satisfied: botocore<1.32.0,>=1.31.73 in /opt/conda/lib/python3.10/site-packages (from boto3) (1.31.73)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from boto3) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.17.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.15,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.14.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: PyMuPDFb==1.23.5 in /opt/conda/lib/python3.10/site-packages (from PyMuPDF) (1.23.5)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.4.39)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.8.6)\n",
      "Requirement already satisfied: anyio<4.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.5.0)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.52 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.0.54)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.4.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (3.3)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<4.0->langchain) (1.2.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.73->boto3) (2.8.2)\n",
      "Requirement already satisfied: urllib3<2.1,>=1.25.4 in /opt/conda/lib/python3.10/site-packages (from botocore<1.32.0,>=1.31.73->boto3) (2.0.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.8.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<7.0,>=1.4.0->sagemaker==2.194.0) (3.8.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->sagemaker==2.194.0) (3.0.9)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.10.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (1.1.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from google-pasta->sagemaker==2.194.0) (1.16.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker==2.194.0) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker==2.194.0) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->sagemaker==2.194.0) (0.10.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->sagemaker==2.194.0) (2022.1)\n",
      "Requirement already satisfied: ppft>=1.7.6.7 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker==2.194.0) (1.7.6.7)\n",
      "Requirement already satisfied: dill>=0.3.7 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker==2.194.0) (0.3.7)\n",
      "Requirement already satisfied: pox>=0.3.3 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker==2.194.0) (0.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.15 in /opt/conda/lib/python3.10/site-packages (from pathos->sagemaker==2.194.0) (0.70.15)\n",
      "Requirement already satisfied: contextlib2>=0.5.5 in /opt/conda/lib/python3.10/site-packages (from schema->sagemaker==2.194.0) (21.6.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (0.4.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade sagemaker==2.194.0 boto3 transformers  PyMuPDF langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7277db14-856d-4b57-93fe-98dcd85464a7",
   "metadata": {},
   "source": [
    "### Restart the kernel to ensure all packages are enabled "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81161d43-1e84-4263-8ecb-837cd1327e7a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Part 1 Deploy the Llama-2-13b LLM model as sagemake rendpoint on inf2.48xlarge instance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7edff8b2-9383-4cd1-85a2-3133f1a62b81",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('2.194.0', '1.28.73')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import Model, image_uris \n",
    "import io\n",
    "sagemaker.__version__, boto3.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cb7215a-1cbc-422f-b264-083c2b843d16",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /root/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "AWS_REGION=\"us-east-1\"\n",
    "boto3_session=boto3.session.Session(region_name=AWS_REGION)\n",
    "smr = boto3.client('sagemaker-runtime', region_name=AWS_REGION)\n",
    "sm = boto3.client('sagemaker', region_name=AWS_REGION)\n",
    "role = sagemaker.get_execution_role()\n",
    "sess = sagemaker.session.Session(boto3_session,                                 \n",
    "                                 sagemaker_client=sm,\n",
    "                                 sagemaker_runtime_client=smr) # sagemaker session for interacting with different AWS APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "526f2d04-a599-4dae-8fff-9a24e93e4387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instance_type = \"ml.inf2.48xlarge\" \n",
    "model_name=\"smep-inf2-llama2-13b-chat-model\"\n",
    "endpoint_name = f\"{model_name}-endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e82e0a8-1ed1-461c-bf5d-fd978358d4a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## You can change these values if you have your own container image and model weights stored in S3\n",
    "prefix='torchserve'\n",
    "external_image_uri = '102048127330.dkr.ecr.us-east-1.amazonaws.com/neuronx:2-14-1'\n",
    "external_s3_uri = f\"s3://gai-model-artifacts/{prefix}/model_store/llama-2-13b-chat/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af47ce13-10d8-4422-9af8-eaa2235276df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## instantiate model instance \n",
    "model = Model(\n",
    "name=model_name,\n",
    "# Enable SageMaker uncompressed model artifacts model_data={\n",
    "model_data = {    \n",
    "    \"S3DataSource\": {\n",
    "                \"S3Uri\": external_s3_uri,\n",
    "                \"S3DataType\": \"S3Prefix\",\n",
    "                \"CompressionType\": \"None\",\n",
    "        }\n",
    "    },\n",
    "    image_uri=external_image_uri,\n",
    "    role=role,\n",
    "    sagemaker_session=sess,\n",
    "    env={\"TS_INSTALL_PY_DEP_PER_MODEL\": \"true\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc71515-3fd9-45b4-b83b-ca6d6913f85a",
   "metadata": {},
   "source": [
    "#### Next, we will deploy the LLM as sagemaker endpoint. It can take upto 15 minutes to deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b6eaa18-9f39-4d73-a184-428df1868285",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your model is not compiled. Please compile your model before using Inferentia.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!CPU times: user 110 ms, sys: 5.73 ms, total: 115 ms\n",
      "Wall time: 8min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.deploy( \n",
    "    initial_instance_count=1,\n",
    "    instance_type=instance_type,\n",
    "    endpoint_name=endpoint_name,\n",
    "    volume_size=512, # increase the size to store large model, mandatory for inf2 instance types\n",
    "    model_data_download_timeout=3600, # increase the timeout to download large model \n",
    "    container_startup_health_check_timeout=600, # increase the timeout to load large model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "925838f0-6f5a-4340-9f89-16ff2e2b7c95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "## define class to parse the streaming responses when endpoint is invoked\n",
    "\n",
    "class Parser: \n",
    "    \"\"\"\n",
    "    A helper class for parsing the byte stream input.\n",
    "    The output of the model will be in the following format:\n",
    "    ```\n",
    "    b'{\"outputs\": [\" a\"]}\\n'\n",
    "    b'{\"outputs\": [\" challenging\"]}\\n'\n",
    "    b'{\"outputs\": [\" problem\"]}\\n'\n",
    "    ...\n",
    "    ```\n",
    "    While usually each PayloadPart event from the event stream will contain a byte\n",
    "array\n",
    "    with a full json, this is not guaranteed and some of the json objects may be split\n",
    "across\n",
    "    PayloadPart events. For example:\n",
    "    ```\n",
    "    {'PayloadPart': {'Bytes': b'{\"outputs\": '}}\n",
    "    {'PayloadPart': {'Bytes': b'[\" problem\"]}\\n'}}\n",
    "    This class accounts for this by concatenating bytes written via the 'write'\n",
    "function\n",
    "    and then exposing a method which will return lines (ending with a '\\n' character)\n",
    "within\n",
    "    the buffer via the 'scan_lines' function. It maintains the position of the last\n",
    "read\n",
    "    position to ensure that previous bytes are not exposed again.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self): \n",
    "        self.buff = io.BytesIO() \n",
    "        self.read_pos = 0\n",
    "\n",
    "    def write(self, content): \n",
    "        self.buff.seek(0, io.SEEK_END) \n",
    "        self.buff.write(content)\n",
    "        data = self.buff.getvalue()\n",
    "\n",
    "    def scan_lines(self): \n",
    "        self.buff.seek(self.read_pos)\n",
    "        for line in self.buff.readlines():\n",
    "            if line[-1] != b'\\n': \n",
    "                self.read_pos += len(line) \n",
    "                yield line[:-1]\n",
    "\n",
    "    def reset(self): \n",
    "        self.read_pos = 0\n",
    "        \n",
    "\n",
    "## define a function to return inference results\n",
    "\n",
    "def run_infer(endpoint_name, body):\n",
    "    resp = smr.invoke_endpoint_with_response_stream(EndpointName=endpoint_name,\n",
    "                                                    Body=body,\n",
    "                                                    ContentType=\"application/json\")\n",
    "    event_stream = resp['Body'] \n",
    "    parser = Parser()\n",
    "    results = ''\n",
    "    for event in event_stream:\n",
    "        parser.write(event['PayloadPart']['Bytes']) \n",
    "        for line in parser.scan_lines():\n",
    "            #print(line.decode(\"utf-8\"), end=' ')\n",
    "            results = results + line.decode(\"utf-8\") + ' '\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "53167c30-4896-4eb7-8ba1-d3787ca063e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the result of inference request #1 \n",
      "\n",
      " User: Explain the self-attention mechanism that Transformers use like I'm ten years old.           Assistant: Sure! So, you know how sometimes you're talking to someone and you want to make sure they understand what you're saying? Like, you might say \"Hey, did you hear me?\" or \"Can you repeat that back to me?\"           That's kind of like what the self-attention mechanism does in Transformers. It's like a way for the model to say \"Hey, did you hear me?\" to itself, and then listen to what it just said to make sure it's correct.           So, imagine you're trying to translate a sentence from English to Spanish. The self-attention mechanism would let the model look at each word in the sentence, and then say \"Hey, did I get this right?\" to itself. If it didn't get it right, it would listen to what it just said and try again.           It's like having a little voice in your head that's always checking to make sure you're understanding what you're saying, and then adjusting what you say based on that. Does that make sense \n",
      "CPU times: user 56.5 ms, sys: 8.83 ms, total: 65.4 ms\n",
      "Wall time: 42.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "body = \"\"\"User: Explain the self-attention mechanism that Transformers use like I'm ten years old.\n",
    "          Assistant:\"\"\".encode('utf-8')\n",
    "results = run_infer(endpoint_name, body)\n",
    "print(f'This is the result of inference request #1 \\n\\n {results}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931c2288-63a6-4d73-ab7d-02ece0a2547e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "body2 = \"\"\"\n",
    "    Write a concise summary of the text, return your responses with 2 lines that cover\n",
    "the key points of the following text.\n",
    "    ```\n",
    "    Intended Use\n",
    "    Intended Use Cases Llama 2 is intended for commercial and research use in English.\n",
    "    Tuned models are intended for assistant-like chat, whereas pretrained models can\n",
    "be\n",
    "    adapted for a variety of natural language generation tasks.\n",
    "    To get the expected features and performance for the chat versions, a\n",
    "    specific formatting needs to be followed, including the INST and <<SYS>> tags,\n",
    "    BOS and EOS tokens, and the whitespaces and breaklines in between (\n",
    "        we recommend calling strip() on inputs to avoid double-spaces).\n",
    "        See our reference code in github for details: chat_completion.\n",
    "    Out-of-scope Uses Use in any manner that violates applicable laws or regulations\n",
    "    (including trade compliance laws).Use in languages other than English.\n",
    "    Use in any other way that is prohibited by the Acceptable Use Policy and Licensing\n",
    "Agreement for Llama 2.\n",
    "    ```\n",
    "    SUMMARY:\n",
    "    \"\"\".encode('utf-8')\n",
    "results = run_infer(endpoint_name, body2)\n",
    "print(f'This is the response for warm up inference request #2:\\n\\n {results}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0264b8f-2166-46c9-ae9b-3c7304d6b37e",
   "metadata": {},
   "source": [
    "## Run benchmark tests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e4b399-e125-46c2-9ef4-8927871d23f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import time\n",
    "import json\n",
    "from transformers import GPT2Tokenizer\n",
    "import pandas as pd \n",
    "\n",
    "## function to initialize gpt2 tokenizer\n",
    "## we will use tokenizer to count input and output tokens \n",
    "\n",
    "def get_tokenizer(id=\"gpt2\"): \n",
    "    try:\n",
    "        tokenizer=GPT2Tokenizer.from_pretrained(id)\n",
    "        print(f'retrieved tokenizer: {id}') \n",
    "    except:\n",
    "        tokenizer=None\n",
    "        print(f'unable to retrieve tokenizer: {id}')\n",
    "    return tokenizer\n",
    "\n",
    "## function to return count of tokens in the text \n",
    "\n",
    "def get_token_count(tokenizer, content: str) -> int: \n",
    "    try:\n",
    "        encoded = tokenizer(content)\n",
    "        count = len(encoded['input_ids']) \n",
    "    except:\n",
    "        print(f'error counting tokens tokenizer not available')\n",
    "        count = 0\n",
    "    return count\n",
    "\n",
    "def run_test(prompts: list): \n",
    "    results = []\n",
    "    prompt_id = 0\n",
    "    tokenizer = get_tokenizer() \n",
    "    for prompt in prompts:\n",
    "    \n",
    "        if prompt_id >= len(prompts): \n",
    "            break\n",
    "\n",
    "        is_error = 0\n",
    "        start_time = time.time()\n",
    "        try:\n",
    "            print(f'prompt id: {prompt_id + 1}')\n",
    "            input_token_count = get_token_count(tokenizer, prompt)\n",
    "            print(f'input token count: {input_token_count}')\n",
    "            start_time = time.time()\n",
    "            body = prompt.encode('utf-8')\n",
    "            response = smr.invoke_endpoint(EndpointName=endpoint_name,\n",
    "                                            Body=body,\n",
    "                                            ContentType=\"application/json\")\n",
    "            end_time = time.time()\n",
    "            latency_ms=int((end_time - start_time)*1000)\n",
    "            print(f'duration(ms): {latency_ms}')\n",
    "            response = response[\"Body\"].read().decode(\"utf8\") \n",
    "            #response = json.loads(response)\n",
    "            #output = response[0]['generation']\n",
    "            output_token_count = get_token_count(tokenizer, response)\n",
    "            print(f'output token count: {output_token_count}')\n",
    "        except:\n",
    "            print(e)\n",
    "            is_error = 1\n",
    "            latency_ms=0\n",
    "            input_token_count = 0\n",
    "            output_token_count = 0\n",
    "            end_time = time.time()\n",
    "\n",
    "        detail = {\n",
    "                \"start_time\": datetime.fromtimestamp(start_time).strftime(\"%Y-%m-%d%H:%M:%S.%f\")[:-3],\n",
    "                \"end_time\": datetime.fromtimestamp(end_time).strftime(\"%Y-%m-%d%H:%M:%S.%f\")[:-3],\n",
    "                \"input_token_count\":input_token_count,\n",
    "                \"output_token_count\":output_token_count,\n",
    "                \"latency_ms\": latency_ms\n",
    "         }\n",
    "        results.append(detail)\n",
    "        prompt_id += 1 \n",
    "\n",
    "    print(f'completed test')\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4245f43-fa77-488f-93a0-df45892271cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Run the benchmark tests\n",
    "\n",
    "test_prompts = [\n",
    "    \"User: give me a recipe for an old fashioned cocktail\\nAssistant:\",\n",
    "    \"User: Write a poem about open source machine learning. \\nAssistant:\",\n",
    "    \"User: give me a recipe for home made mayonnaise \\nAssistant:\",\n",
    "    \"User: Explain generative AI to me like I am a 5th grade student who is 12 years old. \\nAssistant:\",\n",
    "    \"User: Respond to this question only based on the information provided here. Cats like dogs, and dogs like rabbits. Cats like anything that dogs like. I really really dislike rabbits. How do cats feel about rabbits?\\nAssistant:\"\n",
    "]\n",
    "results = run_test(prompts=test_prompts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e560bf-877a-4bea-9e7f-6046896cbc63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame.from_dict(results)\n",
    "print(f\"\"\"Mean Output Tokens : {results['output_token_count'].mean()} tokens\"\"\")\n",
    "print(f\"\"\"Mean Latency : {results['latency_ms'].mean()} milliseconds\"\"\")\n",
    "print(f\"\"\"Total Output Tokens : {results['output_token_count'].sum()} tokens\"\"\")\n",
    "print(f\"\"\"Total Duration : {results['latency_ms'].sum()/1000.0} seconds\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce66c5d-3527-41d5-94a6-187350f52e71",
   "metadata": {},
   "source": [
    "## Last Step: Clean up endpoint and associated artifacts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cab6fd-111f-41e3-9a68-e88c350818d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sm.delete_endpoint(EndpointName=endpoint_name)\n",
    "sm.delete_endpoint_config(EndpointConfigName=endpoint_name)\n",
    "sm.delete_model(ModelName=model_name)\n",
    "print('Cleanup Done!')"
   ]
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.2xlarge",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
